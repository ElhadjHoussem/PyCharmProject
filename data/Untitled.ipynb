{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=r\"Passing\", category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image,ImageOps\n",
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "'''Global Variables'''\n",
    "########################################################################################################################\n",
    "\n",
    "LABELS=['Neutral','Happy','Sad','Surprise','Fear','Disgust','Anger','Contempt']\n",
    "NUM_CLASSES = len(LABELS)\n",
    "\n",
    "ZIP_FILE_NAME = \"J:/Emotion/AffectNet.zip\"\n",
    "RECORD_RIR=\"../DataSet/AffectNet/AffectNetRecords_64x64_gray_4/\"\n",
    "ANNOTATION_SUFFIX_KEYS=['aro','val','exp']\n",
    "ANNOTATION_TYPES={'aro':'float','val' :'float','exp':'int'}\n",
    "DATA_DICT_KEYS=['image','expression','arousal','valence']\n",
    "\n",
    "ANNOTATION_MAP={annotation:key  for annotation in ANNOTATION_SUFFIX_KEYS for key in DATA_DICT_KEYS if annotation in key}\n",
    "\n",
    "IMAGE_SIZE=64\n",
    "COLORS=['RGB','GRAY']\n",
    "COLOR=COLORS[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "'''TF_RECORD HELPER Functions'''\n",
    "########################################################################################################################\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))): # if value is tensor\n",
    "        value = value.numpy() # get value of tensor\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a floast_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "def serialize_array(array):\n",
    "  array = tf.io.serialize_tensor(array)\n",
    "  return array\n",
    "########################################################################################################################\n",
    "''' TF_RECORD Feature Mapping Function'''\n",
    "########################################################################################################################\n",
    "def ensure_dir(dir_path):\n",
    "    directory = os.path.dirname(dir_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "'''while writing Record'''\n",
    "def parse_single_image(DataPoint):\n",
    "\n",
    "    #define the dictionary -- the structure -- of a single example\n",
    "    data = {\n",
    "      'raw_image': _bytes_feature(serialize_array(DataPoint['image'])),\n",
    "      'height': _int64_feature(int(DataPoint['image'].shape[0])),\n",
    "      'width': _int64_feature(int(DataPoint['image'].shape[1])),\n",
    "      'expression': _int64_feature(int(DataPoint['expression'])),\n",
    "      'arousal': _float_feature(float(DataPoint['arousal'])),\n",
    "      'valence': _float_feature(float(DataPoint['valence']))\n",
    "    }\n",
    "    #create an Example, wrapping the single features\n",
    "    out = tf.train.Example(features=tf.train.Features(feature=data))\n",
    "\n",
    "    return out\n",
    "'''while reading Record'''\n",
    "def parse_tfr_element(element):\n",
    "\n",
    "    data = {\n",
    "        'raw_image' : tf.io.FixedLenFeature([], tf.string),\n",
    "        'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'width':tf.io.FixedLenFeature([], tf.int64),\n",
    "        'expression':tf.io.FixedLenFeature([], tf.int64),\n",
    "        'arousal':tf.io.FixedLenFeature([], tf.float32),\n",
    "        'valence':tf.io.FixedLenFeature([], tf.float32)\n",
    "    }\n",
    "\n",
    "    content = tf.io.parse_single_example(element, data)\n",
    "\n",
    "    raw_image = content['raw_image']\n",
    "    height = content['height']\n",
    "    width = content['width']\n",
    "    expression = content['expression']\n",
    "    arousal = content['arousal']\n",
    "    valence = content['valence']\n",
    "\n",
    "\n",
    "    #get our 'feature'-- our image -- and reshape it appropriately\n",
    "    image = tf.io.parse_tensor(raw_image, out_type=tf.uint8)\n",
    "    image = tf.reshape(image, shape=[height,width])\n",
    "\n",
    "    return image, expression,arousal,valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_point_from_zipFile(file_name,data_dict_keys,annotation_Suffix_keys,annotation_map,annotation_types):\n",
    "    Data_point={key:None for key in data_dict_keys}\n",
    "    Annotations = {key:None for key in annotation_Suffix_keys}\n",
    "    with ZipFile(file_name,'r') as zip_archive:\n",
    "        for file in zip_archive.namelist():\n",
    "            paths = file.split(sep='/')\n",
    "            if paths[1] == 'annotations':\n",
    "                annotation_suffix = paths[-1].split('_')[-1].split('.')[0]\n",
    "                if annotation_suffix in annotation_Suffix_keys:\n",
    "                    Annotations[annotation_suffix]=np.load(zip_archive.open(file))\n",
    "                    Annotation_Loaded = not (None in Annotations.values())\n",
    "                    if Annotation_Loaded:\n",
    "                        for annotation_suffix in annotation_Suffix_keys:\n",
    "                            Annotations[annotation_suffix]=np.array(Annotations[annotation_suffix],dtype=annotation_types[annotation_suffix])\n",
    "                        image_path = paths[0]+'/images/'+paths[-1].split('_')[0]+'.jpg'\n",
    "                        image_file = zip_archive.open(image_path)\n",
    "                        image = Image.open(image_file)\n",
    "                        if COLOR=='GRAY':\n",
    "                            image = ImageOps.grayscale(image)\n",
    "                        Data_point['image'] = np.array(image.resize((IMAGE_SIZE,IMAGE_SIZE)))\n",
    "                        for Annotation_key in annotation_Suffix_keys:\n",
    "                            Data_point[annotation_map[Annotation_key]]=Annotations[Annotation_key]\n",
    "\n",
    "                        yield Data_point\n",
    "                        Data_point={key:None for key in data_dict_keys}\n",
    "                        Annotations = {key:None for key in annotation_Suffix_keys}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_point_by_label_(label=0):\n",
    "    data_gen = load_data_point_from_zipFile(ZIP_FILE_NAME,\n",
    "                                        DATA_DICT_KEYS,\n",
    "                                        ANNOTATION_SUFFIX_KEYS,\n",
    "                                        ANNOTATION_MAP,\n",
    "                                        ANNOTATION_TYPES) \n",
    "    i =0\n",
    "    count=0\n",
    "    while True:\n",
    "        current_data = next(data_gen,None)     \n",
    "        if i ==0: \n",
    "            print(current_data)\n",
    "\n",
    "        if current_data is None:\n",
    "            data_gen = load_data_point_from_zipFile(ZIP_FILE_NAME,\n",
    "                                    DATA_DICT_KEYS,\n",
    "                                    ANNOTATION_SUFFIX_KEYS,\n",
    "                                    ANNOTATION_MAP,\n",
    "                                    ANNOTATION_TYPES)\n",
    "            print('reached_EOF and continue at iteration{} with count {}'.format(i,count))\n",
    "            current_data = next(data_gen,None)\n",
    "            print(current_data)\n",
    "\n",
    "        exp = int(current_data['expression'])\n",
    "        i+=1\n",
    "\n",
    "        if exp==label:\n",
    "            yield current_data\n",
    "            count+=1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_point_by_label(label=0):\n",
    "    data_gen = load_data_point_from_zipFile(ZIP_FILE_NAME,\n",
    "                                        DATA_DICT_KEYS,\n",
    "                                        ANNOTATION_SUFFIX_KEYS,\n",
    "                                        ANNOTATION_MAP,\n",
    "                                        ANNOTATION_TYPES) \n",
    "    i =0\n",
    "    while True:\n",
    "        count=0\n",
    "        for index,current_data in enumerate(data_gen):\n",
    "            if index==0:\n",
    "                print(current_data)\n",
    "            exp = int(current_data['expression'])\n",
    "            if exp==label:\n",
    "                yield current_data\n",
    "                count+=1\n",
    "        print('reached_EOF  with count {} and continue '.format(count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': array([[148, 135, 115, ..., 176, 173, 176],\n",
      "       [135, 120, 100, ..., 177, 176, 178],\n",
      "       [116,  96,  84, ..., 176, 177, 176],\n",
      "       ...,\n",
      "       [  8,  12,  96, ..., 131, 132, 131],\n",
      "       [  8,  10,  73, ..., 132, 133, 132],\n",
      "       [  9,   9,  46, ..., 131, 132, 131]], dtype=uint8), 'expression': array(1), 'arousal': array(-0.0555556), 'valence': array(0.785714)}\n",
      "{'image': array([[148, 135, 115, ..., 176, 173, 176],\n",
      "       [135, 120, 100, ..., 177, 176, 178],\n",
      "       [116,  96,  84, ..., 176, 177, 176],\n",
      "       ...,\n",
      "       [  8,  12,  96, ..., 131, 132, 131],\n",
      "       [  8,  10,  73, ..., 132, 133, 132],\n",
      "       [  9,   9,  46, ..., 131, 132, 131]], dtype=uint8), 'expression': array(1), 'arousal': array(-0.0555556), 'valence': array(0.785714)}\n",
      "{'image': array([[148, 135, 115, ..., 176, 173, 176],\n",
      "       [135, 120, 100, ..., 177, 176, 178],\n",
      "       [116,  96,  84, ..., 176, 177, 176],\n",
      "       ...,\n",
      "       [  8,  12,  96, ..., 131, 132, 131],\n",
      "       [  8,  10,  73, ..., 132, 133, 132],\n",
      "       [  9,   9,  46, ..., 131, 132, 131]], dtype=uint8), 'expression': array(1), 'arousal': array(-0.0555556), 'valence': array(0.785714)}\n",
      "{'image': array([[148, 135, 115, ..., 176, 173, 176],\n",
      "       [135, 120, 100, ..., 177, 176, 178],\n",
      "       [116,  96,  84, ..., 176, 177, 176],\n",
      "       ...,\n",
      "       [  8,  12,  96, ..., 131, 132, 131],\n",
      "       [  8,  10,  73, ..., 132, 133, 132],\n",
      "       [  9,   9,  46, ..., 131, 132, 131]], dtype=uint8), 'expression': array(1), 'arousal': array(-0.0555556), 'valence': array(0.785714)}\n",
      "{'image': array([[148, 135, 115, ..., 176, 173, 176],\n",
      "       [135, 120, 100, ..., 177, 176, 178],\n",
      "       [116,  96,  84, ..., 176, 177, 176],\n",
      "       ...,\n",
      "       [  8,  12,  96, ..., 131, 132, 131],\n",
      "       [  8,  10,  73, ..., 132, 133, 132],\n",
      "       [  9,   9,  46, ..., 131, 132, 131]], dtype=uint8), 'expression': array(1), 'arousal': array(-0.0555556), 'valence': array(0.785714)}\n",
      "{'image': array([[148, 135, 115, ..., 176, 173, 176],\n",
      "       [135, 120, 100, ..., 177, 176, 178],\n",
      "       [116,  96,  84, ..., 176, 177, 176],\n",
      "       ...,\n",
      "       [  8,  12,  96, ..., 131, 132, 131],\n",
      "       [  8,  10,  73, ..., 132, 133, 132],\n",
      "       [  9,   9,  46, ..., 131, 132, 131]], dtype=uint8), 'expression': array(1), 'arousal': array(-0.0555556), 'valence': array(0.785714)}\n",
      "{'image': array([[148, 135, 115, ..., 176, 173, 176],\n",
      "       [135, 120, 100, ..., 177, 176, 178],\n",
      "       [116,  96,  84, ..., 176, 177, 176],\n",
      "       ...,\n",
      "       [  8,  12,  96, ..., 131, 132, 131],\n",
      "       [  8,  10,  73, ..., 132, 133, 132],\n",
      "       [  9,   9,  46, ..., 131, 132, 131]], dtype=uint8), 'expression': array(1), 'arousal': array(-0.0555556), 'valence': array(0.785714)}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-13ad09719091>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m287653\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_data_point_by_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-8888235315fb>\u001b[0m in \u001b[0;36mload_data_point_by_label\u001b[1;34m(label)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurrent_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-25abdd649359>\u001b[0m in \u001b[0;36mload_data_point_from_zipFile\u001b[1;34m(file_name, data_dict_keys, annotation_Suffix_keys, annotation_map, annotation_types)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mData_point\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_dict_keys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mAnnotations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mannotation_Suffix_keys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mzip_archive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip_archive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\envs\\anaconda\\envs\\MasterPy37\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[0;32m   1256\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m                 \u001b[1;31m# set the modified flag so central directory gets written\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\envs\\anaconda\\envs\\MasterPy37\\lib\\zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1379\u001b[0m                             t>>11, (t>>5)&0x3F, (t&0x1F) * 2 )\n\u001b[0;32m   1380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1381\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decodeExtra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1382\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader_offset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\envs\\anaconda\\envs\\MasterPy37\\lib\\zipfile.py\u001b[0m in \u001b[0;36m_decodeExtra\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    466\u001b[0m                     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<QQQ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mln\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m                     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<QQ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mln\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m                     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<Q'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(287653):\n",
    "    next(load_data_point_by_label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object load_data_point_from_zipFile at 0x0000019715F7A1C8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen = [load_data_point_from_zipFile(ZIP_FILE_NAME,\n",
    "                                        DATA_DICT_KEYS,\n",
    "                                        ANNOTATION_SUFFIX_KEYS,\n",
    "                                        ANNOTATION_MAP,\n",
    "                                        ANNOTATION_TYPES) for _ in range(len(LABELS))]\n",
    "datasdata_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_in_tfr_from_zip(zip_file_name=ZIP_FILE_NAME,tfrecord_filename:str=\"_AffectNet\", chunk_size:int=10, out_dir:str=RECORD_RIR):\n",
    "    tf.enable_eager_execution()\n",
    "    ensure_dir(RECORD_RIR)\n",
    "    total_image = count_annotation(zip_file_name)\n",
    "    #determine the number of shards (single TFRecord files) we need:\n",
    "    splits = (total_image//chunk_size) + 1 #determine how many tfr shards are needed\n",
    "    if total_image%chunk_size == 0:\n",
    "        splits-=1\n",
    "    print(f\"\\nUsing {splits} shard(s) for {total_image} files, with up to {chunk_size} samples per shard\")\n",
    "\n",
    "    file_count = 0\n",
    "    rest= total_image\n",
    "    data_gen = load_data_point_from_zipFile(zip_file_name,\n",
    "                                            DATA_DICT_KEYS,\n",
    "                                            ANNOTATION_SUFFIX_KEYS,\n",
    "                                            ANNOTATION_MAP,\n",
    "                                            ANNOTATION_TYPES)\n",
    "    \n",
    "    for i in tqdm(range(splits),desc=\"Global Progress All-Files \"+\" {} -> {}\".format(file_count,total_image)):\n",
    "        current_shard_name = \"{}{}_{}{}.tfrecords\".format(out_dir, i+1, splits, tfrecord_filename)\n",
    "        writer = tf.io.TFRecordWriter(current_shard_name)\n",
    "        current_shard_count = 0\n",
    "        chunk_size = chunk_size if rest>chunk_size else rest\n",
    "        for _ in tqdm(range(chunk_size),desc=\"Local Progress File \"+ current_shard_name + \" {} ->{} \".format(current_shard_count,chunk_size)):\n",
    "\n",
    "            try:\n",
    "                current_data = next(data_gen,None)\n",
    "                exp = int(current_data['expression'])\n",
    "                print(int(exp))\n",
    "\n",
    "\n",
    "                #create the required Example representation\n",
    "                out = parse_single_image(DataPoint=current_data)\n",
    "\n",
    "                writer.write(out.SerializeToString())\n",
    "                current_shard_count+=1\n",
    "                file_count += 1\n",
    "                rest = total_image - file_count\n",
    "            except:\n",
    "                print('no more data in zip file')\n",
    "\n",
    "        writer.close()\n",
    "    print(f\"\\nWrote {file_count} elements to TFRecord\")\n",
    "    return file_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetV1Adapter' object has no attribute 'as_numpy_iterator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-071535556777>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRECORD_RIR\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"*_AffectNet.tfrecords\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparse_tfr_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DatasetV1Adapter' object has no attribute 'as_numpy_iterator'"
     ]
    }
   ],
   "source": [
    "file=tf.data.Dataset.list_files(RECORD_RIR+'/'+str(0)+'/'+\"*_AffectNet.tfrecords\")\n",
    "dataset = tf.data.TFRecordDataset(file).map(parse_tfr_element).batch(1)\n",
    "dataset = dataset.as_numpy_iterator()\n",
    "print(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_record(label_class=0):\n",
    "    file=tf.data.Dataset.list_files(RECORD_RIR+'/'+str(label_class)+'/'+\"*_AffectNet.tfrecords\")\n",
    "    count=0\n",
    "    for image,exp,valence,aro in tf.data.TFRecordDataset(file).map(parse_tfr_element):\n",
    "        print(image)\n",
    "        count+=1\n",
    "        if count>10:\n",
    "            break\n",
    "    print(\"label {} count {}\".format(label_class,count))\n",
    "    tf.disable_eager_execution()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\envs\\anaconda\\envs\\MasterPy37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "tf.Tensor(\n",
      "[[  8   6   9 ...  36  53  47]\n",
      " [  9   8   8 ...  33  32  32]\n",
      " [  6   8   6 ...  39  43  42]\n",
      " ...\n",
      " [200 180 184 ...  44  37  54]\n",
      " [206 188 184 ...  51  92 128]\n",
      " [189 195 192 ... 141 200 228]], shape=(64, 64), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[  4   2   2 ... 194 177 183]\n",
      " [  2   1   2 ... 198 168 168]\n",
      " [  2   2   3 ... 197 171 154]\n",
      " ...\n",
      " [ 58  69  83 ... 205 203 200]\n",
      " [ 91 107 106 ... 207 204 203]\n",
      " [ 97 112 121 ... 206 207 206]], shape=(64, 64), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[213 213 207 ... 102 103 104]\n",
      " [213 207 168 ... 105 100 105]\n",
      " [210 179 150 ... 102  99 104]\n",
      " ...\n",
      " [167 167 167 ...  16  17  22]\n",
      " [166 168 174 ...  28  22  20]\n",
      " [178 197 209 ...  36  32  25]], shape=(64, 64), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[113  85 132 ...  23  26  30]\n",
      " [116 104 140 ...  24  27  28]\n",
      " [103 121 144 ...  23  29  31]\n",
      " ...\n",
      " [ 92 173 114 ... 117 115 129]\n",
      " [118 170  68 ... 118 117 119]\n",
      " [173 142  73 ... 121 124 135]], shape=(64, 64), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[180 183 180 ... 180 180 180]\n",
      " [183 181 175 ... 181 181 182]\n",
      " [184 176 173 ... 182 183 182]\n",
      " ...\n",
      " [209 209 205 ... 214 216 219]\n",
      " [208 208 207 ... 214 216 218]\n",
      " [208 208 208 ... 217 217 217]], shape=(64, 64), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[135 136 142 ... 255 254 253]\n",
      " [134 135 142 ... 253 253 252]\n",
      " [133 134 137 ... 253 253 251]\n",
      " ...\n",
      " [ 29  26  22 ... 198 104 112]\n",
      " [ 32  28  23 ...  60  71 142]\n",
      " [ 33  28  23 ...  34  52 110]], shape=(64, 64), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[57 48 22 ...  1  1  1]\n",
      " [50 41 28 ...  2  1  1]\n",
      " [50 40 30 ...  2  1  1]\n",
      " ...\n",
      " [61 20  7 ... 28 15 36]\n",
      " [46 20 29 ... 11 16 30]\n",
      " [35 13 20 ...  8 30 64]], shape=(64, 64), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[123 125 117 ... 158 143 135]\n",
      " [125 120 108 ... 154 141 134]\n",
      " [125 121 107 ... 149 139 134]\n",
      " ...\n",
      " [132 132 126 ... 146 168 183]\n",
      " [133 133 128 ... 169 184 183]\n",
      " [133 133 131 ... 186 184 183]], shape=(64, 64), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[ 27  25  23 ... 199 245 202]\n",
      " [ 27  25  23 ...  44 202 236]\n",
      " [ 28  25  22 ...   1  45 200]\n",
      " ...\n",
      " [  5  13  21 ... 102 103 102]\n",
      " [  4  13  20 ... 102 102 102]\n",
      " [  5  13  21 ... 100  99 100]], shape=(64, 64), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[ 95  95  97 ... 133 133 131]\n",
      " [ 97  98  98 ... 131 133 129]\n",
      " [111 107 102 ... 132 129 127]\n",
      " ...\n",
      " [ 15  25  30 ...  19  15  12]\n",
      " [ 15  24  29 ...  46  14  14]\n",
      " [ 16  24  23 ...  74  32  13]], shape=(64, 64), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[34 33 36 ... 29 22 35]\n",
      " [33 32 37 ... 24 27 42]\n",
      " [29 30 38 ... 23 33 38]\n",
      " ...\n",
      " [46 54 42 ... 51 43 37]\n",
      " [54 51 38 ... 47 43 40]\n",
      " [55 50 40 ... 44 44 43]], shape=(64, 64), dtype=uint8)\n",
      "label 0 count 11\n"
     ]
    }
   ],
   "source": [
    "test_record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RECORD_RIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ee0df4499ee9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mwrite_data_in_tfr_with_merged_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfr_dir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRECORD_RIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"*_AffectNet.tfrecords\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mcounts_label_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m74874\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m134415\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m25459\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'3'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m14090\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'4'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m6378\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'5'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m3803\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'6'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m24882\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'7'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m3750\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_size_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.7\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcounts_label_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfiles_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfr_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RECORD_RIR' is not defined"
     ]
    }
   ],
   "source": [
    "def write_data_in_tfr_with_merged_classes(chunk_size=5000,tfr_dir:str=RECORD_RIR, pattern:str=\"*_AffectNet.tfrecords\"):\n",
    "    counts_label_classes = {'0': 74874,'1': 134415,'2': 25459,'3': 14090,'4': 6378,'5': 3803,'6': 24882,'7': 3750}\n",
    "\n",
    "    train_size_list = [int(0.7 * counts_label_classes[str(l)]) for l in range(len(LABELS))]\n",
    "    files_list = [tf.data.Dataset.list_files(tfr_dir+str(i)+'/'+pattern) for i in range(len(LABELS))]\n",
    "\n",
    "    full_datasets_list = [tf.data.TFRecordDataset(files)for files in files_list]\n",
    "\n",
    "    train_dataset_list = [full_datasets_list[l].take(train_size_list[l]) for l in range(len(LABELS))]\n",
    "    val_dataset_list = [full_datasets_list[l].skip(train_size_list[l])for l in range(len(LABELS))]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    count=0\n",
    "    for data in zip([train_dataset.map(parse_tfr_element)] for train_dataset in train_dataset_list ):\n",
    "        data_0,*_ = data\n",
    "        #image,exp,valence,aro = data_0\n",
    "        print(data[0])\n",
    "        #print(valence_1,valence)\n",
    "        count+=1\n",
    "        if count>=3:\n",
    "            break\n",
    "    print(\"count {}\".format(count))\n",
    "    \n",
    "    \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<DatasetV1Adapter shapes: ((?, ?), (), (), ()), types: (tf.uint8, tf.int64, tf.float32, tf.float32)>]\n",
      "[<DatasetV1Adapter shapes: ((?, ?), (), (), ()), types: (tf.uint8, tf.int64, tf.float32, tf.float32)>]\n",
      "[<DatasetV1Adapter shapes: ((?, ?), (), (), ()), types: (tf.uint8, tf.int64, tf.float32, tf.float32)>]\n",
      "count 3\n"
     ]
    }
   ],
   "source": [
    "write_data_in_tfr_with_merged_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(i):\n",
    "    count=1\n",
    "    while count<10:\n",
    "        yield count\n",
    "        count+=i\n",
    "ones= generate(3)\n",
    "twos=generate(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1]\n",
      "[6, 3]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "#generators=zip([gen for gen in generate(3)],[gen for gen in generate(2)])\n",
    "#generators=zip([gen for gen in generate(i)] for i in range(3))\n",
    "#ziped = map(zip:[gen for gen in generators[i]] for i  in range(2) )\n",
    "result1 = map(lambda *a: [a_ for a_ in a] ,generate(5),generate(2))\n",
    "\n",
    "for i in result1: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ones_twoes in ziped:\n",
    "    print(ones_twoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "(1, 2)\n",
      "(1, 2)\n",
      "(1, 2)\n",
      "(1, 2)\n",
      "(1, 2)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "ones=[1,1,1,1,1,1,1]\n",
    "twos=[2,2,2,2,2,2,2]\n",
    "for one_two in zip(ones,twos):\n",
    "    print(one_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [9,7,3,5,19,17,13,15,29,27,23,25]\n",
    "inputs2 = [4,8,2,6,14,18,12,16]\n",
    "outputs=[0,1,0,1,0,1,0,1,0,1,0,1]\n",
    "outputs2=[0,2,0,2,0,2,0,2]\n",
    "dataset_1=tf.data.Dataset.from_tensor_slices((inputs,outputs))\n",
    "dataset_2=tf.data.Dataset.from_tensor_slices((inputs2,outputs2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=446, shape=(), dtype=int32, numpy=9>, <tf.Tensor: id=447, shape=(), dtype=int32, numpy=0>)\n",
      "(<tf.Tensor: id=450, shape=(), dtype=int32, numpy=9>, <tf.Tensor: id=451, shape=(), dtype=int32, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset_1.take(1).repeat(2):\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_1 = [9,7,3,5,19,17,13,15,29,27,23,25]\n",
    "# inputs_2 = [4,8,2,6,14,18,12,16,24,28,22,26]\n",
    "\n",
    "databatch_1 = dataset_1.batch(4)\n",
    "databatch_2 = dataset_2.batch(4)\n",
    "datamerge_1 = databatch_1.concatenate(databatch_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'concatenate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e99250126623>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minputs_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputs_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0minputs_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputs_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0minputs_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'concatenate'"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for batch_1,batch_2 in zip(databatch_1,databatch_2):\n",
    "    #batch = batch_1.concatenate(batch_2)\n",
    "    inputs_1,outputs_1 = batch_1\n",
    "    inputs_2,outputs_2 = batch_2\n",
    "    inputs_1.concatenate(inputs_2)\n",
    "    print('batch'+str(i),inputs_1)\n",
    "    i+=1\n",
    "    if (i>100):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = [9,7,3,5,  19,17,13,15, 29,27,23,25]\n",
    "# inputs2 = [4,8,2,6, 14,18,12,16]\n",
    "i=0\n",
    "for batch_1,batch_2 in zip(databatch_1,databatch_2):\n",
    "    input_1,output_1 = batch_1\n",
    "    input_2,output_2 = batch_2\n",
    "    print('batch'+str(i),tf.random.shuffle(tf.concat((batch_1[0],batch_2[0],batch_2[0]),axis=0)))\n",
    "    i+=1\n",
    "    if (i>100):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for inp,out in datamerge_1:\n",
    "    i+=1\n",
    "    print('batch'+str(i),inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = [9,7,3,5,19,17,13,15,29,27,23,25]\n",
    "# inputs2 = [4,8,2,6,14,18,12,16,24,28,22,26]\n",
    "\n",
    "datamerge_2=dataset_1.concatenate(dataset2).batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for inp,out in datamerge_2:\n",
    "    i+=1\n",
    "    print('batch'+str(i),inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = [9,7,3,5,19,17,13,15,29,27,23,25]\n",
    "# inputs2 = [4,8,2,6,14,18,12,16,24,28,22,26]\n",
    "\n",
    "datamerge_3=dataset_1.take(4).concatenate(dataset2.take(4)).repeat(4).batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for inp,out in datamerge_3:\n",
    "    i+=1\n",
    "    print('batch'+str(i),inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = [9,7,3,5,19,17,13,15,29,27,23,25]\n",
    "# inputs2 = [4,8,2,6,14,18,12,16,24,28,22,26]\n",
    "\n",
    "dataset_1=dataset_1.batch(4)\n",
    "dataset_2=dataset_1.batch(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for inp in map(tf.concat,dataset_1.batch(4),dataset_2.batch(4)):\n",
    "    i+=1\n",
    "    print('batch'+str(i),inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
